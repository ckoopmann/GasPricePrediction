\chapter{Experimental Design}
While designing an experiment to evaluate the performance of the LSTM model in comparison to reference models one has to solve several problems regarding the following topics:
\begin{enumerate}
\item Preprocessing\begin{itemize}
	\item How should missing data be treated ?
	\item Should input and output features be scaled, if yes how?
\end{itemize}
\item Reference models\begin{itemize}
	\item Which models should be selected as references ?
\end{itemize}
\item Parameter tuning \begin{itemize}
	\item How should the tuning process be designed (Train / validation split, tuning grid)? 
	\item Which hyper parameters should be tuned and which should be set to a fixed value ?
\end{itemize}
\item Variable selection \begin{itemize}
	\item How should the selection process be designed (Forward vs. backward selection)? 
\end{itemize}
\item Model evaluation \begin{itemize}
\item Which data should be selected as test data by excluding it from parameter tuning and variable selection ?
\item How should the selection process be designed ((Train / test split)? 
\end{itemize}	
\end{enumerate}

A major challenge arising from this problem is the interdependence between the parameter tuning and the variable selection steps. To tune the parameters one has to have selected a certain set of input variables and vice versa. One way to solve this problem would be to view the subset of selected input variables as just another tuning parameter and integrate both steps. However in this process the number of training iterations that would have to be performed would increase significantly to the product of the iterations in both steps. To avoid excessive computational costs the following alternative approach was chosen:

\begin{enumerate}
\item Perform parameter tuning on \textit{univariate} models
\item Perform variable selection using parameter values determined in step 1.
\item Tune parameters again for models using input variables determined in step 2.
\item Evaluate both the tuned univariate models from step 1 as well as multivariate models from step 3. 
\end{enumerate}
Each of these steps is executed both for the LSTM model as well as for each reference model for which it is applicable.
A \textit{univariate} model in this context is a model trained using only past observations of the front month price as input, whereas multivariate models use both the front month price as well as at least one additional input variable. In the following paragraphs the selected approach for each of the above mentioned decision problems is outlined.

\section{Preprocessing}
Due to the high quality of the time series data on the \textit{Thomson Reuters Eikon} data platform, the amount of preprocessing necessary for this prediction problem was relatively limited. The preprocessing steps that are probably most interesting and have the most effect on the results were the treatment of missing data and the feature scaling for the price level prediction.
\subsection{Treatment of missing data}
As mentioned in section \ref{Sec:Data-Availability} the majority of incomplete observations are due to the fact that some variables are available only from a relatively late starting point relative to the target variable. To ensure that the different models are trained on the same amount and quality of data independent of the input variables of each model, all observations for the time period where some of the variables have not yet been observed at all is dropped from the training and testing data set entirely. The cases of missing data for some variables after that time period are mostly due to different number of trading days for the various financial assets as well as some variables not being recorded on a daily basis. Due to this fact and the observations that variables are rarely missing for more than a few days in a row a forward filling replacement strategy has been chosen, replacing missing observations with the last non-missing observation of that variable.
\subsection{Feature scaling}
For both the binary as well as the price level prediction problem the input data is scaled to values in the interval $[-1,1]$ using the Min-Max scaling approach as implemented in the \textit{scikit-learn} package. This scaling approach is based on the following formula: \begin{align*}
\tilde{x}_t = 2\frac{x_t - \min_{t \in T_{train}}(x_t)}{\max_{t \in T_{train}}(x_t)-\min_{t \in T_{train}}(x_t)} - 1
\end{align*}
Note that the minimum and maximum is determined on the training data only to avoid including information from the test dataset. Although theoretically this could lead to values of the target variable outside of the desired interval in the test set changing this approach has not shown any effect on the results and therefore the more rigorous approach with regard to train-test separation has been chosen. For the price level prediction the target variable is also scaled using this approach in order to ensure that it is within the value range of the $tanh$ function.
\section{Reference Models}
The predictions of the LSTM model are compared to each of the following reference models:
\begin{description}
\item[Simple Recurrent Neural Network (RNN):] This model is the implementation of the above outlined simple RNN architecture where the hidden layer output of the past time step is used as another input variable.
\item[Feed Forward Neural Network (FFNN):] The FFNN model is an implementation of the classical Neural Network without any recurrent connection, modelling  a static input output mapping. 
\item[Regression Models:] This reference model consists of a Feed Forward Neural Network without any hidden layer. The model therefore just applies the output activation function on a linear combination of the input variables. In the case of the binary prediction problem  where a logistic activation function is used, this is equivalent to a logistic regression, with the difference that the model is trained using gradient descent instead of maximum likelihood. In the case of the price level prediction the $tanh$ function is applied to the linear combination resulting in a somewhat unconventional variant of a generalised linear model.
\item[Lagged Price Level:] This reference forecast for the price level prediction is generated by just choosing today's price level as prediction for the closing price of the next trading day. It therefore represents the market expectation of the price.
\item[Equal Distribution:] This reference for the binary prediction problem is based on the assumption that all remaining trading days are equally likely to deliver the minimal closing price. Therefore the probability forecast for the current trading day to be minimal is: \begin{align*}
\tilde{y}^{binary}_{t,M} = \frac{1}{N^{remaining}_{t,M}}
\end{align*}
In this case $N^{remaining}_{t,M}$ represents the number of trading days that remain in month $M$ starting from and including trading day $t$.
\end{description}


\section{Parameter Tuning}
The detailed structure of each model as well as the training process is controlled by a number of hyper parameters. The selection of parameters, that are considered in this paragraph, as well as the terminology is inspired by the \textit{Tensorflow} and \textit{Keras} Python packages, which were used to implement the neural network based models. Theoretically the models could be tuned on all of these parameters. However using the standard grid search used in this tuning approach the total number of parameter combinations would grow exponentially. Since each of the models have to be retrained on every parameter combination this would generate excessive computational costs. To avoid these costs the parameters are separated into a set of fixed hyper-parameters which are set to constant values derived from experience and literature and a complimentary set of tuning parameters.
\subsection{Fixed Hyper-Parameters}
This section will give a brief description of each hyper-parameter that was excluded from the tuning process. This selection was done based on observations from literature as well as the online machine learning community. Except for the \textit{length} parameter none of these parameters alter the actual structure of the respective model but are limited to the training process. The \textit{length} and \textit{batchsize} parameters can be considered features of the \textit{Tensorflow} package and are not necessarily present in the theoretical work on neural networks or alternative implementations.
\begin{description}
\item[Length:] From the definition of a recurrent neural network there is no theoretic limit on the length of inter temporal dependencies that the model can learn. This is due to the fact, that the gradient as well as the layer activations can flow infinitely far through the network. Regarding the implementation this would also mean that there is no limit on the amount of calculations that would have to be done to determine the gradient based updates to the network weights. Therefore the \textit{Tensorflow} implementation of recurrent neural networks requires the user to pass a length argument which limits the number of time steps that are included in the calculation of the gradients for each observation. This length thereby also limits the maximum length of inter temporal dependencies that the model can learn.

\item[Batchsize:] The \textit{Tensorflow} package processes the training data in batches. In practice that means that at a given training epoch the gradients are calculated for a certain subset of training observations at once. Then the weights are updated using the gradients calculated from this subset. The \textit{batchsize} parameter controls the size of this subset. Therefore in each training step the weights are updated $\frac{n_{obs}}{batchsize}$ times (rounded up to the next integer). Given the same number of training steps a larger \textit{batchsize} therefore means less frequent weight updates, slower learning and less computational complexity.

\item[Epochs:] The \textit{epochs} parameter controls the number of training steps, which is the number of times the weight updates are repeated for each training batch. Therefore the total number of weight updates is $epochs * \frac{n_{obs}}{batchsize}$. 

\item[Loss:] The \textit{loss} parameter determines the loss-function that is minimized during the training of the model. In this work the \textit{Mean Squared Error} (MSE) is used as loss for the price level prediction whereas \textit{Binary Cross Entropy} (BCE) is used for the binary prediction problem. These loss functions are defined in the following way: \begin{align*}
MSE &= \frac{1}{n}\sum_{i=1}^{n}(y_i - \tilde{y_i})^2 \\
BCE &= -\frac{1}{n}\sum_{i=1}^{n}(y_i)log(\tilde{y_i}) + (1-y_i)log(1-\tilde{y_i})
\end{align*}

\item[Optimizer:] The \textit{optimizer} parameter chooses an optimization algorithm to use when minimizing the loss function on the training set. Following practice and advice from the machine learning community the \textit{Stochastic Gradient Descent} optimizer is used for the FFNN models. Following the advice in the \textit{Keras} documentation the \textit{RMSProp} optimizer is used for recurrent models. This optimizer is an extension of the \textit{Stochastic Gradient Descent} method that divides the learning rate at any given iteration by the recent average magnitude of the gradient for each weight.

\item[Output Activation:] The output activation is the function that is applied to the linear combination of hidden layer outputs fed into the output layer. This activation function depends on the target variable. For the binary target variable the $logit$ function is chosen to generate predictions in the interval $[0,1]$. In the case of the price level prediction a $tanh$ activation is chosen generating predictions in the interval $[-1,1]$ which is the value range of the scaled target variable.

\item[Hidden Activation:] For the activation function on the hidden layer the $tanh$ function is chosen for all networks in both prediction problems.
\end{description}
\subsection{Tuning Parameters}
In the parameter tuning stage each model was tuned over the following parameters
\begin{description}
\item[Learning Rate:] The learning rate is the value by which the gradient values in each iteration are multiplied to get the weight updates in the standard \textit{Stochastic Gradient Descent} method. This means that the weight value at epoch $n+1$ ($W_{ij, n+1}$ is calculated as $W_{ij, n+1} = W_{ij, n} - learningrate * \frac{dl(W_{ij, n})}{dW_{ij, n}}$. A lower learning rate slows down the learning process and increases the number of training epochs necessary to converge on a local minimum of the loss function. If the learning rate is too high on the other hand the gradient descent algorithm might not converge at all, constantly "over-shooting" the minimum.
\item[Dropout:] One way to avoid the issue of over-fitting is to randomly drop different input variables at each time step. Using this approach the value of the dropout tuning parameter sets the probability with witch any individual input variable is dropped. Dropout is only tuned in multivariate models whereas in the univariate cases it is set to zero.
\item[Hidden neurons:] This parameter sets the number of neurons in the hidden layer. In the case of the LSTM network it sets the number of neurons for every trainable layer in all gates. Therefore the total number of neurons in the hidden layer of the LSTM is four times that number.
\end{description}
\subsection{Tuning Process}
For the parameter tuning a simple grid is expanded across the selected values for each tuning parameter. The model is then trained on all data up to December 2015 and evaluated using data from 2016 separately for each parameter combination. At the end the parameter combination with the best performance on the test set is selected.
\section{Variable Selection}
To select the most relevant input factor among all variables described above a forward selection method is used. This means that in each iteration of the process separate models are trained adding each of the remaining candidates to the model. Using the same train-test split as in the tuning process the most promising variable is  selected and removed from the set of candidates for the next iteration. This is repeated until five variables have been added. Afterwards the model configuration with the best performance among all sets of selected variables of size one to five is chosen. Note that in all cases the training and test data is limited to complete observations containing values for all candidate variables. This is done to ensure that differences in performance can be attributed to the model choice as opposed to differences in data availability.
\section{Model Evaluation}
In the model evaluation phase the performance of the LSTM is compared to each of the reference models listed above both in its univariate as well as multivariate version. For the univariate version the parameter configurations are used that were determined in the first tuning step, whereas the parameters and input variables of the multivariate models are set according to the results of the second tuning iteration and the variable selection steps. Evaluation is done in a month wise rolling prediction, meaning that for each month from January - July 2017 the model is retrained on all data previous to that month and then tested based on its prediction for that month. Afterwards the mean value of the evaluation metric is calculated across the test months.
