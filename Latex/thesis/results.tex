\chapter{Results}
In the following paragraphs, the results of the above described experiment will be presented and the performance of each model evaluated accordingly for both the price level as well as the binary prediction problem. The interpretation of these results will be left to section \ref{Sec:Conc}.
\section{Price Level Prediction}
As mentioned above, the tuning and variable selection steps were done with a single train test split. This resulted in a training data set that contained $744$ observations and a test data set of $372$ observations.
\subsection{Univariate Parameter Tuning}
In the first step where the univariate version of each model is tuned over the number of hidden neurons and the learning rate, the chosen parameter combinations differ significantly among the different model types. For example for the learning rate the recurrent models end up with a value of $0.001$ whereas the feed forward neural network and the neural network based regression are tuned to higher values. Apart from the difference in the model architecture these results might actually be influence by the different optimizers chosen for each type of model. Regarding the number of hidden neurons it should be noted that this parameter is not tuned for the regression model since by definition this model does not contain any hidden neurons. With regards to this parameter the LSTM is tuned to the highest value in the parameter grid whereas the other two neural networks are tuned to the lowest one. Combined with the effects of the LSTM architecture this causes the LSTM to contain by far the highest number of trainable parameters with a total of $4385$ against $89$ and $25$ parameters for the RNN and FFNN models.
\input{\string"../tables/level_par_tuning_short\string".tex}
\subsection{Variable Selection}
Table \ref{tab:level.var.selection.short} shows the best performing variable combinations of each model when iteratively adding up to five additional variables in a forward selection manner. When analysing the results it is important to keep in mind that using this approach starting with $15$ candidate variables each model was trained $65$ times, which is much higher than the number of parameter combinations in the parameter tuning step. Since best model is chosen over a larger set, it is therefore not surprising that the MSE values are much lower than in those steps. Regarding the different model types it can be observed that the recurrent models are tuned to a lower number of additional input variables than the FFNN and Regression model. UK Storage levels, the front month future at the NBP hub and the electricity base load front month are variables that are selected as inputs across different model types. This indicates that they might actually contain some predictive value as opposed to being just a chance selection resulting from random fluctuations in the tuning process.
\input{\string"../tables/level_var_selection_short\string".tex}
\subsection{Multivariate Parameter Tuning}
In the multivariate tuning the same approach is used as in the univariate case with the difference of adding the dropout as additional tuning variable and using multivariate models with the input variables selected above. Again one can see somewhat similar results to the univariate tuning step regarding the selection of the  learning rate. However in the case of the number of hidden neurons the LSTM is tuned to a lower number whereas the chosen number of neurons for both the RNN as well as FFNN increases. Dropout seems not to bring any additional benefit to model performance with it being tuned to zero for all models but the LSTM.
\input{\string"../tables/level_multivar_par_tuning_short\string".tex}
\subsection{Evaluation}
Resulting from the rolling prediction approach selected for this step all models are trained on a larger amount of training data than in the tuning and variable selection steps. This number increases with each month chosen as test month. In table \ref{tab:level.eval.short} the average value of the MSE across months is shown for each model. From these results one can draw several observations. Firstly the LSTM model outperforms all other neural networks as well as the regression approach both within the univariate as well as multivariate models. Secondly within each model category the univariate version outperforms its equivalent version containing additional inputs. However the most significant observation  might be the fact that none of the models is able to outperform the lagged value approach representing the current market prices. Also there is a big gap between the worst two models represented by the multivariate feed forward neural network and regression models and the rest of the models.
\input{\string"../tables/level_eval_short\string".tex}
Figures \ref{fig:level_evaluation_monthly_multivar} and \ref{fig:level_evaluation_monthly_univar} give  a more detailed impression of the performance of each model across test months, by showing the mean squared error on the test set for each test month selected in the evaluation process. From these graphs a few additional observations can be obtained. Regarding the relative performance of the different models, one can observe that the differences in performance generally diminish over time and that the  overall differences are mainly driven by the earlier months. Also the mean squared error of the best models closely follow that of the lagged value reference model. In fact the remaining difference in performance between the univariate LSTM and the lagged value reference vanishes almost completely in the later months.

\begin{figure}[h!]
  \centering
\includegraphics[width=0.8\textwidth,keepaspectratio]{\string"../../Plots/level_evaluation_monthly_multivar\string".png}
  \caption{Month wise MSE for multivariate models}\label{fig:level_evaluation_monthly_multivar}
\end{figure}

\begin{figure}[h!]
  \centering
\includegraphics[width=0.8\textwidth,keepaspectratio]{\string"../../Plots/level_evaluation_monthly_univar\string".png}
  \caption{Month wise MSE for univariate models}\label{fig:level_evaluation_monthly_univar}
\end{figure}

The consistent similarity in performance among the LSTM and the lagged value references suggest that they might provide very similar  predictions. As figure \ref{fig:level_predictions} shows this in fact true. Graphically the predictions from both approaches are almost indistinguishable even after zooming in on the time frame starting in March 2017.

\begin{figure}[h!]
  \centering
\includegraphics[width=0.8\textwidth,keepaspectratio]{\string"../../Plots/level_predictions\string".png}
  \caption{Predictions LSTM vs. Lagged Value }\label{fig:level_predictions}
\end{figure}

The mean absolute difference between both predictions is in fact only around $6.8$ Euro cents or about $0.38$ percent of the lagged value prediction over the whole test period. In fact this difference is highest in February, which is also the month with the worst performance of the LSTM relative to the Lagged Value approach. 
\FloatBarrier
\section{Binary Prediction}
The binary prediction was evaluated using the same approach, with the same amounts of data and tuning parameters as the price level prediction. To generate a monetary evaluation measure however a simple trading strategy was derived from the predictions of each model and the strategies were compared based on the average price paid for each MWh of natural gas.
\subsection{Univariate Parameter Tuning}
Regarding the learning rate, the univariate parameter tuning results are very similar to those of the price level prediction, with the recurrent models being tuned to significantly lower learning rates than the feed forward neural network and regression model. For the number of hidden layer neurons however both the LSTM and RNN models are tuned to different values.
\input{\string"../tables/binary_par_tuning_short\string".tex}
\subsection{Variable Selection}
For the variable selection one can see a number of similarities to the results of the price level prediction problem. One similarity is the fact that for the LSTM model again only one additional variable is selected, which is the price of TTF gas on the day ahead market in this case. Another similarity is again the selection of the UK Storage levels, NBP front month prices and electricity futures as input variables to the other models. This reinforces the impression that these variables do in fact have some influence on the target variable.
\input{\string"../tables/binary_var_selection_short\string".tex}
\subsection{Multivariate Parameter Tuning}
Just as in the price level prediction case the results of the multivariate tuning process differ significantly from the values selected for the univariate models. A difference that might be noted however is that the values of the target function are much closer to those in the variable selection step. This might be seen as an indicator of more stable results. 
\input{\string"../tables/binary_multivar_par_tuning_short\string".tex}
\subsection{Evaluation}
With respect to the relative ranking of the models according to the evaluation on the test set the results for the binary prediction differ substantially from those of the first prediction problem. One  immediate observations is the very good performance of both the univariate as well as multivariate LSTM which make up the two best performing models according to binary cross entropy. Also unlike in the first prediction problem there is no clear preference for either univariate or multivariate models across model types. Furthermore the base line reference model, which in this case is based on the assumption of equal distribution does not dominate the other models in the way previously observed. In fact all of the models except for the multivariate FFNN and Regression outperform this reference model. 
\input{\string"../tables/binary_eval_short\string".tex}

When looking at the performance of the different models for each test month depicted in figures \ref{fig:binary_evaluation_monthly_multivar} and \ref{fig:binary_evaluation_monthly_univar} the relative performances seem a lot more consistent over time than before. Apart from the equal distribution reference the relative ranking among the models rarely changes, with the LSTM model showing a lower error than other neural networks in almost all of the months. Also the size of the difference among the models does not decrease over time, as was observed above.
\begin{figure}[h!]
  \centering
\includegraphics[width=0.8\textwidth,keepaspectratio]{\string"../../Plots/binary_evaluation_monthly_multivar\string".png}
  \caption{Month wise BCE for multivariate models}\label{fig:binary_evaluation_monthly_multivar}
\end{figure}

\begin{figure}[h!]
  \centering
\includegraphics[width=0.8\textwidth,keepaspectratio]{\string"../../Plots/binary_evaluation_monthly_univar\string".png}
  \caption{Month wise BCE for univariate models}\label{fig:binary_evaluation_monthly_univar}
\end{figure}

\subsection{Trading Strategy}
As stated in the introduction, one of the reasons why this thesis was extended to include the binary prediction problem, was the aim to better support trading decisions of gas buyers in the chemical industry. One advantage of the predictions of the binary model in this respect is the fact that its predictions can be interpreted as the probability of the event that today's gas price is minimal among all remaining trading days. For any given trading day this event occurring would mean that the buyer should purchase all of its remaining projected demand today in order to minimise the price paid. Therefore it gives the decision maker a clearer recommendation than the price level prediction models. Another advantage of these models is the fact that one can very easily derive a trading strategy based on these predictions.
One such trading strategy would be to use the prediction of the binary model as the percentage of the remaining demand to be bought on this trading day. Based on the predictions $\tilde{y}_{t,M}$ for 
trading day $t$ in month $M$ the traded share $\tilde{s}_{t,M}$ of the total demand is calculated as:
\begin{align*}
\forall t > t_0: &\tilde{s}_{t,M} = (\prod_{i = t_{0}}^{t-1}(1-\tilde{y}_{i,M}))\tilde{y}_{t,M}\\
&\tilde{s}_{t_0,M} = \tilde{y}_{t_0,M}
\end{align*}
Besides its simplicity this strategy offers various advantages. One advantage is the flexibility to choose the parameter $t_0$ which represents the earliest trading day to begin buying natural gas. By setting the final prediction to one, it is ensured that the traded shares always add up to one and the whole demand is met. While this did require changing these predictions for models other than the equal distribution model it should be noted that these changes are rather small. This is due to the fact that these predictions were already very close to one since the binary target variable is by definition equal to one at the end of the month. Another advantage of this strategy is that applying it to the equal distribution reference model results in buying the same constant share for all trading days after $t_0$. This can be shown by plugging into the above formula the reference prediction $N_{t,M}$, which is the number of trading days in month $M$ starting from trading day $t$:
\begin{align*}
\forall t > t_0: \tilde{s}_{t,M} &= (\prod_{i = t_{0}}^{t-1}(1-\frac{1}{N_{i,M}}))\frac{1}{N_{t,M}}\\
&= (\prod_{i = t_{0}}^{t-1}(\frac{N_{i,M} - 1}{N_{i,M}}))\frac{1}{N_{t,M}}
\end{align*}
Obviously the number of remaining trading days decreases by one with each trading day and it holds $N_{i,M} - 1 = N_{i+1,M}$. Using this fact one gets:
\begin{align*}
\forall t > t_0: \tilde{s}_{t,M}  &= (\prod_{i = t_{0}}^{t-1}(\frac{N_{i+1,M}}{N_{i,M}}))\frac{1}{N_{t,M}} \\
&= \frac{N_{t,M}}{N_{t_0,M}}\frac{1}{N_{t,M}}\\
&= \frac{1}{N_{t_0,M}}
\end{align*}
This is a somewhat natural and well interpretable buying strategy to  use as reference against which to evaluate the strategies resulting from the data driven models.
The different trading strategies are compared against each other based on the average price that is paid per MWh, which is calculated for each month and model in the following way using the closing prices $P_{t,M}$:
\begin{align*}
\bar{P_M} = \sum_{t \geq t_0}\tilde{s}_{t,M}P_{t,M}
\end{align*}
For the strategy resulting from the equal distribution this corresponds to the equally weighted price average across the trading period. In figures \ref{fig:binary_trade_evaluation_monthly_multivar} and \ref{fig:binary_trade_evaluation_monthly_univar} the monthly values for this metric are plotted for univariate and multivariate models when choosing $t_0$ so as to limit trading to the last two weeks of every month.

\begin{figure}[h!]
  \centering
\includegraphics[width=0.8\textwidth,keepaspectratio]{\string"../../Plots/binary_trade_evaluation_monthly_multivar\string".png}
  \caption{Average prices for multivariate models}\label{fig:binary_trade_evaluation_monthly_multivar}
\end{figure}

\begin{figure}[h!]
  \centering
\includegraphics[width=0.8\textwidth,keepaspectratio]{\string"../../Plots/binary_trade_evaluation_monthly_univar\string".png}
  \caption{Average prices for univariate models}\label{fig:binary_trade_evaluation_monthly_univar}
\end{figure}
Although the picture might be less clear from the graphical analysis, the results in table \ref{tab:binary.trade.short} show that in fact all data driven models result in cheaper prices than the equally weighted trading strategy. The prices reported in this table are calculated by taking the average of the prices paid according to each strategy across all months in the test period. The best performing models on this metric, which are the univariate RNN and LSTM models are able to save almost 6 Euro cents per MWh compared to the benchmark. At first sight this might be considered a very modest saving. However if one applies this saving to a gas user such as a power station with a constant gas demand of one Gigawatt these savings would amount to around half a million Euro per year. 
\input{\string"../tables/binary_trade_short\string".tex}
As the trading strategy that results from each model depends on the choice of $t_0$ so do the average prices achieved by each model. However while the relative ranking among the data driven models does vary for different trading periods, the savings that these models achieve over the equal distribution reference are surprisingly stable. In table \ref{tab:binary.eval.cutoff} the savings per MWh of the strategy resulting from the univariate LSTM are shown when choosing $t_0$ so as to limit trading to the last 1 - 15 trading days. Except for very short trading periods, where the strategies are almost identical, the LSTM achieves positive savings between $3$ and $6.8$ Euro cents. 
\FloatBarrier

