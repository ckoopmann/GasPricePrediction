\chapter{Conclusions}\label{Sec:Conc}
In the following paragraphs the above illustrated results will be used to answer the research questions posed in the introduction. Afterwards a few additional observations and learnings obtained during the work on this thesis will be summarised and an outlook on future possible extensions of this work will be given.
\section{Research Questions}
\subsection{Performance of Recurrent Neural Networks}
When assessing the performance of recurrent neural networks as a forecasting tool the results of the two prediction problems differ quite substantially. In the case of the price level prediction the simple lagged value approach using today's price as prediction for tomorrow outperforms both recurrent and feed forward neural networks. The best performing data driven models in this context are in fact those, whose predictions most closely resemble the lagged value. This lack of a predictive advantage might be explained by two different factors. One possible explanation is the assumption that the highly liquid natural gas market represents a very efficient pricing mechanism whose current price already takes all available information into account. When looking at the literature reviewed above regarding price forecasting of natural gas futures, one does in fact see that the results are quite mixed. Even many of the papers reporting positive performance of machine learning algorithms only compare their models to very similar approaches to evaluate the advantage of a particular feature such as wavelet decomposition or feature selection. Many of these papers do not include a comparison of the model against the price expectations of the market.

The alternative explanation might be a lack of data. Since the data is of only daily granularity and the model training was limited to complete observations, the models were only trained on around 1000 training observations. Especially recurrent neural networks and particularly LSTM models contain a very large number of trainable parameters. In this case the parameters sometimes outnumbered the available training observations by a factor of more than four to one. This makes efficient training of these models as well as avoiding overfitting particularly hard and might also be an explanation of the relatively bad performance of the multivariate models. 

With respect to the binary prediction problem the evaluation yields a much more positive conclusion. On the one hand this might be due to the relatively weaker base line reference model which is based on an equal distribution of the probability of being minimal across the remaining days. Unlike the reference model in the price level prediction this forecast does not contain any information of the current market expectations. This reference is in fact outperformed by all but two of the eight different data driven models. However even among these models the performance of recurrent neural networks compares quite well, with three of the four top ranked models regarding cross entropy being of recurrent structure. 
Looking at the monetary evaluation of the derived trading strategies this picture is confirmed with the top three models all being recurrent.
\subsection{Relative Performance of LSTM}
Comparing the relative performance of the LSTM model with that of the simpler RNN architecture the results are more consistent across the two prediction problems. When looking at the ranking of the models according to the loss function within the uni- and multivariate groups, the LSTM model outperforms the simple RNN in both prediction problems. The picture is slightly different in the monetary evaluation where the univariate simple RNN model slightly outperforms the LSTM, however it should be noted that the model was not optimized on this metric and the ranking slightly changes when choosing a different value for the $t_0$ parameter. Across all prediction problems and evaluation metrics the univariate LSTM model shows a consistently good performance being the best or second best model in all rankings. 
\subsection{Business Value}
The potential business value that the recurrent neural networks developed above can offer as a tool to support the purchasing of natural gas mostly derives from the results of the binary prediction problem. The good performance of the LSTM regarding binary cross entropy suggest that the predictions when interpreted as probability estimates already provide a useful piece of information for human decision making. However the most direct and tangible value is displayed by the good performance of the simple trading strategy derived from these predictions and the savings that can be realised compared to the equal distribution reference. While the performance of a human trader might be a more competitive reference, it should be taken into account that these models could run automatically and thereby realise further savings in personnel costs.
\section{Other Observations}
Beyond the above findings some additional observations were made conducting the work presented in this thesis.
\begin{description}
\item[Input Variables:] Across prediction problems and model type some input variables were repeatedly selected in the variable selection step. These input variables which seem to be of particular importance include the natural gas storage levels in the United Kingdom, the Dutch non-LDZ consumption, Electricity Futures and the front month future price for natural gas at the NBP hub.
\item[Variable Scaling:] During the first attempts at implementing the various models the data was not scaled. Instead both input and target variable were used in the format in which they were downloaded. For the price level prediction that meant using a linear output layer. Especially for this prediction problem but also for the binary prediction the variable scaling improved model performance more than expected.
\end{description}
\section{Outlook}
There are a number of possible ways in which the work in this thesis could be extended:
\begin{description}
\item[Further input variables:] The candidates, that were included in the variable selection, were pre-selected based on expert input from a wider range of possibly relevant variables available on the \textit{Thomson Reuters Eikon} database. This selection could be adjusted to include factors such as LNG markets or weather data. 
\item[Extended parameter tuning grid:] Parameter tuning in this thesis was restricted to three tuning parameters and three to four candidate values for each parameter. This might be extended by either including more candidate values or adding additional tuning parameters such as the batch size or the number of training iterations.
\item[Multi-layer architectures:] All neural networks evaluated in this thesis were limited to architectures with at most one hidden layer. This might be changed to include multi-layer architectures which are present in some of the literature reviewed. 
\item[Multi-step forecasts:] One advantage of recurrent neural networks are their presumptive strength in providing forecasts multiple steps into the future. Extending either of the presented prediction problems to multi-step prediction might unlock additional value in the models.
\item[Wavelet transformation:] One method especially popular in the literature on time series forecasting and often reported to bring significant improvements in accuracy is the combination of machine learning methods with wavelet decomposition. Applying this method to the price level prediction problem could also be a promising way to improve upon these results.
\item[Monetary cost function:] Based on feedback from industry experts the most popular aspect of the work presented above was the performance of the trading strategies based on the binary prediction problems. This success is somewhat surprising considering that the models where not trained to optimize this problem at all. This could be changed by implementing a cost function that represents the average price of this strategy and training the models to minimise this loss. It is reasonable to expect the performance of the strategy to improve thereby increasing the savings an industry user could realise.
\end{description}
